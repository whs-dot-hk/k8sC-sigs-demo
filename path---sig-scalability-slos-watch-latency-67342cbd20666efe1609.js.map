{"version":3,"sources":["webpack:///path---sig-scalability-slos-watch-latency-67342cbd20666efe1609.js","webpack:///./.cache/json/sig-scalability-slos-watch-latency.json"],"names":["webpackJsonp","493","module","exports","data","markdownRemark","html","site","siteMetadata","sigs","pathContext","slug"],"mappings":"AAAAA,cAAc,iBAERC,IACA,SAAUC,EAAQC,GCHxBD,EAAAC,SAAkBC,MAAQC,gBAAkBC,KAAA,4wBAAkxBC,MAASC,cAAgBC,MAAA,ofAA2fC,aAAgBC,KAAA","file":"path---sig-scalability-slos-watch-latency-67342cbd20666efe1609.js","sourcesContent":["webpackJsonp([244218636739636],{\n\n/***/ 493:\n/***/ (function(module, exports) {\n\n\tmodule.exports = {\"data\":{\"markdownRemark\":{\"html\":\"<h2>Watch latency SLI details</h2>\\n<h3>User stories</h3>\\n<ul>\\n<li>As an administrator, if Kubernetes is slow, I would like to know if the root\\ncause of it is slow api-machinery (slow watch) or something farther the path\\n(lack of network bandwidth, slow or cpu-starved controllers, ...)</li>\\n</ul>\\n<h3>Other notes</h3>\\n<ul>\\n<li>Pretty much all control loops in Kubernetes are watch-based. As a result\\nslow watch means slow system in general.</li>\\n<li>Note that how we measure it silently assumes no clock-skew in case of\\ncluster with multiple masters.</li>\\n</ul>\\n<h3>TODOs</h3>\\n<ul>\\n<li>Longer term, we would like to provide some guarantees on watch latency\\n(e.g. 99th percentile of SLI per cluster-day &#x3C;= Xms). However, we are not\\nthere yet.</li>\\n</ul>\"},\"site\":{\"siteMetadata\":{\"sigs\":[\"sig-api-machinery\",\"sig-apps\",\"sig-architecture\",\"sig-auth\",\"sig-autoscaling\",\"sig-aws\",\"sig-azure\",\"sig-big-data\",\"sig-cli\",\"sig-cloud-provider\",\"sig-cluster-lifecycle\",\"sig-cluster-ops\",\"sig-contributor-experience\",\"sig-docs\",\"sig-gcp\",\"sig-ibmcloud\",\"sig-instrumentation\",\"sig-multicluster\",\"sig-network\",\"sig-node\",\"sig-openstack\",\"sig-product-management\",\"sig-release\",\"sig-scalability\",\"sig-scheduling\",\"sig-service-catalog\",\"sig-storage\",\"sig-testing\",\"sig-ui\",\"sig-vmware\",\"sig-windows\"]}}},\"pathContext\":{\"slug\":\"/sig-scalability/slos/watch-latency/\"}}\n\n/***/ })\n\n});\n\n\n// WEBPACK FOOTER //\n// path---sig-scalability-slos-watch-latency-67342cbd20666efe1609.js","module.exports = {\"data\":{\"markdownRemark\":{\"html\":\"<h2>Watch latency SLI details</h2>\\n<h3>User stories</h3>\\n<ul>\\n<li>As an administrator, if Kubernetes is slow, I would like to know if the root\\ncause of it is slow api-machinery (slow watch) or something farther the path\\n(lack of network bandwidth, slow or cpu-starved controllers, ...)</li>\\n</ul>\\n<h3>Other notes</h3>\\n<ul>\\n<li>Pretty much all control loops in Kubernetes are watch-based. As a result\\nslow watch means slow system in general.</li>\\n<li>Note that how we measure it silently assumes no clock-skew in case of\\ncluster with multiple masters.</li>\\n</ul>\\n<h3>TODOs</h3>\\n<ul>\\n<li>Longer term, we would like to provide some guarantees on watch latency\\n(e.g. 99th percentile of SLI per cluster-day &#x3C;= Xms). However, we are not\\nthere yet.</li>\\n</ul>\"},\"site\":{\"siteMetadata\":{\"sigs\":[\"sig-api-machinery\",\"sig-apps\",\"sig-architecture\",\"sig-auth\",\"sig-autoscaling\",\"sig-aws\",\"sig-azure\",\"sig-big-data\",\"sig-cli\",\"sig-cloud-provider\",\"sig-cluster-lifecycle\",\"sig-cluster-ops\",\"sig-contributor-experience\",\"sig-docs\",\"sig-gcp\",\"sig-ibmcloud\",\"sig-instrumentation\",\"sig-multicluster\",\"sig-network\",\"sig-node\",\"sig-openstack\",\"sig-product-management\",\"sig-release\",\"sig-scalability\",\"sig-scheduling\",\"sig-service-catalog\",\"sig-storage\",\"sig-testing\",\"sig-ui\",\"sig-vmware\",\"sig-windows\"]}}},\"pathContext\":{\"slug\":\"/sig-scalability/slos/watch-latency/\"}}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/json-loader!./.cache/json/sig-scalability-slos-watch-latency.json\n// module id = 493\n// module chunks = 244218636739636"],"sourceRoot":""}